{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389156db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements.txt\n",
    "#https://github.com/alexklibisz/elastiknn/blob/main/examples/tutorial-notebooks/multimodal-search-amazon-products.ipynb\n",
    "#https://towardsdatascience.com/computing-node-embedding-with-a-graph-database-neo4j-its-graph-data-science-library-d45db83e54b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from vectordocutil import *\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint, pformat\n",
    "from IPython.display import Image, display, Markdown, Code, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from faker import Faker\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "from elasticsearch_dsl import connections\n",
    "from elasticsearch_dsl.query import MultiMatch, Match\n",
    "\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68cc767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "fake = Faker(['en_US'])\n",
    "fake.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ba431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(string)\n",
    "embeddingsTXT = model.encode(\" \".join(string), show_progress_bar=True)\n",
    "embeddingsTXT = np.array([embedding for embedding in embeddingsTXT]).astype(\"float32\")\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float64\")\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15711b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = [\n",
    "    [i for i in range(768)],\n",
    "    [[embeddings[j] for i in range(1)] for j in range(768)]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783f738",
   "metadata": {},
   "source": [
    "## Connect to Neo4j for extracting embeddings out of the graph via GDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d78b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3fa5cb6",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup for OpenSearch\n",
    "#https://opensearch.org/downloads.html\n",
    "#1. Set up your Docker host environment\n",
    "#    * macOS & Windows: In Docker Preferences > Resources, set RAM to at least 4 GB.\n",
    "#    * Linux: Ensure vm.max_map_count is set to at least 262144 as per the documentation.\n",
    "#2. Download docker-compose.yml into your desired directory\n",
    "#3. Run docker-compose up\n",
    "#4. Have a nice coffee while everything is downloading and starting up\n",
    "#5. Navigate to http://localhost:5601/ for OpenSearch Dashboards\n",
    "#6. Login with the default username (admin) and password (admin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e088e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elasticsearch: OpenSarch, OpenDistro, Elastic\n",
    "#https://www.elastic.co/guide/en/elasticsearch/client/python-api/master/connecting.html\n",
    "#https://elasticsearch-dsl.readthedocs.io/en/latest/search_dsl.html\n",
    "#https://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "#curl -XGET https://localhost:9200 -u admin:admin --insecure  \n",
    "#https://github.com/elastic/elasticsearch-py/issues/712\n",
    "#curl -XGET https://localhost:9200/_cat/indices -u admin:admin --insecure \n",
    "\n",
    "client = Elasticsearch()\n",
    "connections.create_connection(hosts=['https://localhost:9200'], timeout=20, use_ssl=False, verify_certs=False,http_auth=(\"admin:admin\"))\n",
    "#scheme=\"http\", use_ssl=False, verify_certs=False, \n",
    "\n",
    "#es = Elasticsearch([\"http://localhost:9200\"])\n",
    "#es.info\n",
    "#es.cluster.health(wait_for_status='yellow', request_timeout=1)\n",
    "\n",
    "s = Search(index=\"indices\").query(\"match\", title=\"python\")\n",
    "\n",
    "\n",
    "#es.cluster.health(wait_for_status='yellow', request_timeout=1)\n",
    "\n",
    "#response = s.execute()\n",
    "#print('Total %d hits found.' % response.hits.total)\n",
    "#for h in response:\n",
    "#    print(h.title, h.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31feff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = s.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f25ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this does work on mac terminal, not via Jupyter Notebook\n",
    "#https://elasticsearch-py.readthedocs.io/en/v8.5.2/\n",
    "#https://github.com/pgolding/elasticsearch/blob/master/index.py\n",
    "\n",
    "#this flow does work via terminal, but not in jupyter notebook\n",
    "try:\n",
    "    es = Elasticsearch(\"https://admin:admin@localhost:9200\",\n",
    "                           use_ssl = False,\n",
    "                           ca_certs=False,\n",
    "                           verify_certs=False)\n",
    "    print(\"Connection to ES Server successful\")\n",
    "    \n",
    "    for i in es.indices.get_alias(\"*\"):\n",
    "        print(i)\n",
    "except:\n",
    "    print(\"Unable to connect to server\")\n",
    "    exit(1)\n",
    "#this flow does work via terminal, but not in jupyter notebook\n",
    "\n",
    "    \n",
    "doc = {\n",
    "    'author': 'kimchy',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool.',\n",
    "    'timestamp': datetime.now(),\n",
    "}\n",
    "resp = es.index(index=\"test-index\", id=1, document=doc)\n",
    "print(resp['result'])\n",
    "\n",
    "resp = es.get(index=\"test-index\", id=1)\n",
    "print(resp['_source'])\n",
    "\n",
    "es.indices.refresh(index=\"test-index\")\n",
    "\n",
    "resp = es.search(index=\"test-index\", query={\"match_all\": {}})\n",
    "print(\"Got %d Hits:\" % resp['hits']['total']['value'])\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5853d0",
   "metadata": {},
   "source": [
    "## Creating syntetic dataset for document key-word queries combined with vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf59f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dims = 256\n",
    "reduced = iter_vectors_reduced(fname_vectors, dims=vector_dims, samples=10000)\n",
    "\n",
    "for (asin, vec) in islice(reduced(fname_vectors), 3):\n",
    "  print(asin, len(vec), vec[:3])\n",
    "\n",
    "sample = np.array([v for (_, v) in islice(reduced(fname_vectors), 20000)])\n",
    "plt.title(\"Shape: %s, mean: %.3f\" % (sample.shape, sample.mean()))\n",
    "plt.hist(np.ravel(sample), bins=40, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'fakeDocs'\n",
    "source_no_vecs = ['tittle', 'abstract']\n",
    "\n",
    "#function to generate yield list of items to insert into elastic\n",
    "def docs():\n",
    "  for p in tqdm(iter_products(fname_products)):\n",
    "    yield { \n",
    "      \"_op_type\": \"index\", \n",
    "      \"_index\": \"h_ocid\", \n",
    "      \"_id\": p[\"asin\"], \n",
    "      \"title\": p.get(\"title\", None), \n",
    "      \"abstract\": p.get(\"abstract\", None)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e907db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(1)\n",
    "    return x + y\n",
    "\n",
    "@delayed\n",
    "def incD(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "@delayed\n",
    "def addD(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4763e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 774 µs, sys: 535 µs, total: 1.31 ms\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x = inc(1)\n",
    "y = inc(2)\n",
    "z = add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3434de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 305 µs, sys: 398 µs, total: 703 µs\n",
      "Wall time: 1.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x = delayed(incD)(1)\n",
    "y = delayed(incD)(2)\n",
    "z = delayed(addD)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6956e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.47 ms, sys: 693 µs, total: 3.17 ms\n",
      "Wall time: 2.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "z.compute()\n",
    "\n",
    "#https://examples.dask.org/delayed.html\n",
    "#https://examples.dask.org/applications/evolving-workflows.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6759ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.bmc.com/blogs/elasticsearch-commands/\n",
    "#https://opensearch.org/docs/1.0/search-plugins/knn/approximate-knn/\n",
    "#https://medium.com/@bb8s/embedding-based-retrieval-approximate-nearest-neighbor-algorithms-used-in-production-systems-b96dd4b2e9a3\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from faker import Faker\n",
    "\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "fake = Faker(['en_US'])\n",
    "\n",
    "#https://github.com/ueg1990/faker-schema\n",
    "#to generate a json\n",
    "\n",
    "#Pipeline\n",
    "#    Load json file in a collection\n",
    "#    Function returns yield item ocid and string joined ocid’s\n",
    "#    Function returns yield item ocid and vectorized string\n",
    "#    Function returns yield item ocid and Fake doc{ +vectorized string}\n",
    "#    Iteration over last item to send each item to OpenSearch and append final doc to a collection\n",
    "#    Operation to save as json the collection\n",
    "#    \n",
    "#    pipelining with dask?\n",
    "#    https://examples.dask.org/applications/prefect-etl.html\n",
    "#       https://docs.prefect.io/getting-started/installation/\n",
    "\n",
    "#load json OCID into collection\n",
    "f = open('../subtree/subtrees1.json')\n",
    "data = json.load(f) #OCID->[OCID]\n",
    "f.close()\n",
    "\n",
    "#function to convert key-list into key-(string:joined ocid words)\n",
    "def listToJoinedWords(ls):\n",
    "    \" \".join(ls)\n",
    "\n",
    "#function to convert string: joined ocid words into vectorized embedding representation\n",
    "def stringToVector(md, string):\n",
    "    md.encode(string, show_progress_bar=False)\n",
    "    \n",
    "#function receives embedded representation and creates the document for being later sent to elastic\n",
    "def vectorEnhancedDoc(key, vector):\n",
    "    doc = {\n",
    "            \"_op_type\": \"index\", \n",
    "            \"_index\": index, \n",
    "            \"_id\": p[\"asin\"], \n",
    "            \"id\": key\n",
    "            \"vector\": vector,\n",
    "            \"k\": faker.\n",
    "    }\n",
    "    \n",
    "\n",
    "#to pipeline https://examples.dask.org/delayed.html\n",
    "    \n",
    "#routine to send docs to elastic and append key-doc to a collection\n",
    "\n",
    "#routine to create a collection for later save to disk key-doc data structure. Facilitate the test\n",
    "#OCID->DOC{[OCID].toString().toVector} json.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delayed functions\n",
    "\n",
    "listToJoinedWordsD = dask.delayed(listToJoinedWords)\n",
    "stringToVectorD = dask.delayed(stringToVector)\n",
    "vectorEnhancedDocD = dask.delayed(vectorEnhancedDoc)\n",
    "\n",
    "for i in data:\n",
    "    x = listToJoinedWordsD(i)\n",
    "    y = stringToVectorD(x)\n",
    "    z = add(x, y)\n",
    "    zs.append(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb52086",
   "metadata": {},
   "source": [
    "## Create the Elasticsearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f15bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk insert\n",
    "bulk(es, docs(), chunk_size=2000, max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://opensearch.org/docs/1.0/search-plugins/knn/approximate-knn/\n",
    "PUT /h_ocid\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"my_vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 768,\n",
    "        \"method\": {\n",
    "            \"name\": \"hnsw\",\n",
    "            \"space_type\": \"cosinesimil\",\n",
    "            \"engine\": \"nmslib\",\n",
    "            \"parameters\": {\n",
    "              \"ef_construction\": 256,\n",
    "              \"m\": 48\n",
    "            }\n",
    "        }\n",
    "      },\n",
    "    \"seq_ocid\": { \"type\": \"text\" }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98796906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = \"myindex\"\n",
    "source_no_vecs = ['vector']\n",
    "\n",
    "body = {\n",
    "  \"query\": {\n",
    "        \"knn\": {\n",
    "          \"my_vector\": {\n",
    "            \"vector\": [1, 1.5],\n",
    "                \"k\": 5\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "res = es.search(index=index, body=body, size=5, _source=source_no_vecs)\n",
    "\n",
    "#zsh: segmentation fault  python\n",
    "#https://github.com/UKPLab/sentence-transformers/issues/1319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"elastiknn\": True,\n",
    "    \"number_of_shards\": 1,\n",
    "    \"number_of_replicas\": 0\n",
    "  }\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "  \"dynamic\": False,\n",
    "  \"properties\": {\n",
    "    \"asin\": { \"type\": \"keyword\" },\n",
    "    \"imVecElastiknn\": {\n",
    "      \"type\": \"elastiknn_dense_float_vector\",\n",
    "      \"elastiknn\": {\n",
    "        \"dims\": vector_dims,\n",
    "        \"model\": \"lsh\",\n",
    "        \"similarity\": \"angular\",\n",
    "        \"L\": 60,\n",
    "        \"k\": 3\n",
    "      }\n",
    "    },\n",
    "    \"imVecXpack\": {\n",
    "      \"type\": \"dense_vector\",\n",
    "      \"dims\": vector_dims\n",
    "    },\n",
    "    \"title\": { \"type\": \"text\" },\n",
    "    \"description\": { \"type\": \"text\" },\n",
    "    \"price\": { \"type\": \"float\" },\n",
    "    \"imUrl\": { \"type\": \"text\" }\n",
    "  }\n",
    "}\n",
    "\n",
    "if not es.indices.exists(index):\n",
    "  es.indices.create(index, settings)\n",
    "  es.indices.put_mapping(mapping, index)\n",
    "es.indices.get_mapping(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenSearch queries\n",
    "PUT /myindex\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"my_vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 2\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "PUT /h_ocid\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"my_vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 768\n",
    "      },\n",
    "    \"seq_ocid\": { \"type\": \"text\" }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "PUT /myindex/_doc/1\n",
    "{\n",
    "  \"my_vector\": [1.5, 2.5]\n",
    "}\n",
    "\n",
    "PUT /myindex/_doc/2\n",
    "{\n",
    "  \"my_vector\": [2.5, 3.5]\n",
    "} \n",
    "\n",
    "POST /myindex/_search\n",
    "{\n",
    "  \"size\": 2,\n",
    "  \"query\": {\n",
    "    \"knn\": {\n",
    "      \"my_vector\": {\n",
    "        \"vector\": [1, 1.5],\n",
    "        \"k\": 5\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "#combine the knn query clause with other query clauses\n",
    "POST /myindex/_search\n",
    "{\n",
    "  \"size\": 5,\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": {\n",
    "        \"knn\": {\n",
    "          \"my_vector\": {\n",
    "            \"vector\": [3, 4],\n",
    "            \"k\": 5\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"filter\": {\n",
    "        \"range\": {\n",
    "          \"price\": {\n",
    "            \"lt\": 15\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
