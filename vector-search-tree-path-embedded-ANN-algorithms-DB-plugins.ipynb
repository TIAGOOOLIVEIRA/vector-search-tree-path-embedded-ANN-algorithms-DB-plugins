{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389156db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements.txt\n",
    "#https://github.com/alexklibisz/elastiknn/blob/main/examples/tutorial-notebooks/multimodal-search-amazon-products.ipynb\n",
    "#https://towardsdatascience.com/computing-node-embedding-with-a-graph-database-neo4j-its-graph-data-science-library-d45db83e54b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from vectordocutil import *\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint, pformat\n",
    "from IPython.display import Image, display, Markdown, Code, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc1f5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "fake = Faker(['en_US'])\n",
    "fake.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31a47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cafa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(string)\n",
    "embeddingsTXT = model.encode(\" \".join(string), show_progress_bar=True)\n",
    "embeddingsTXT = np.array([embedding for embedding in embeddingsTXT]).astype(\"float32\")\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float64\")\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23611875",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = [\n",
    "    [i for i in range(768)],\n",
    "    [[embeddings[j] for i in range(1)] for j in range(768)]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d031473",
   "metadata": {},
   "source": [
    "## Connect to Neo4j for extracting embeddings out of the graph via GDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a7da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e4b799",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096acbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup for OpenSearch\n",
    "#https://opensearch.org/downloads.html\n",
    "#1. Set up your Docker host environment\n",
    "#    * macOS & Windows: In Docker Preferences > Resources, set RAM to at least 4 GB.\n",
    "#    * Linux: Ensure vm.max_map_count is set to at least 262144 as per the documentation.\n",
    "#2. Download docker-compose.yml into your desired directory\n",
    "#3. Run docker-compose up\n",
    "#4. Have a nice coffee while everything is downloading and starting up\n",
    "#5. Navigate to http://localhost:5601/ for OpenSearch Dashboards\n",
    "#6. Login with the default username (admin) and password (admin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "es = Elasticsearch([\"http://localhost:9200\"])\n",
    "es.cluster.health(wait_for_status='yellow', request_timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f204be5",
   "metadata": {},
   "source": [
    "## Creating syntetic dataset for document key-word queries combined with vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677acc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dims = 256\n",
    "reduced = iter_vectors_reduced(fname_vectors, dims=vector_dims, samples=10000)\n",
    "\n",
    "for (asin, vec) in islice(reduced(fname_vectors), 3):\n",
    "  print(asin, len(vec), vec[:3])\n",
    "\n",
    "sample = np.array([v for (_, v) in islice(reduced(fname_vectors), 20000)])\n",
    "plt.title(\"Shape: %s, mean: %.3f\" % (sample.shape, sample.mean()))\n",
    "plt.hist(np.ravel(sample), bins=40, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'fakeDocs'\n",
    "source_no_vecs = ['tittle', 'abstract']\n",
    "\n",
    "#function to generate yield list of items to insert into elastic\n",
    "def docs():\n",
    "  for p in tqdm(iter_products(fname_products)):\n",
    "    yield { \n",
    "      \"_op_type\": \"index\", \n",
    "      \"_index\": index, \n",
    "      \"_id\": p[\"asin\"], \n",
    "      \"title\": p.get(\"title\", None), \n",
    "      \"abstract\": p.get(\"abstract\", None)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd078c",
   "metadata": {},
   "source": [
    "## Create the Elasticsearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4a2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c618fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk insert\n",
    "bulk(es, docs(), chunk_size=2000, max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eecd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "settings = {\n",
    "  \"settings\": {\n",
    "    \"elastiknn\": True,\n",
    "    \"number_of_shards\": 1,\n",
    "    \"number_of_replicas\": 0\n",
    "  }\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "  \"dynamic\": False,\n",
    "  \"properties\": {\n",
    "    \"asin\": { \"type\": \"keyword\" },\n",
    "    \"imVecElastiknn\": {\n",
    "      \"type\": \"elastiknn_dense_float_vector\",\n",
    "      \"elastiknn\": {\n",
    "        \"dims\": vector_dims,\n",
    "        \"model\": \"lsh\",\n",
    "        \"similarity\": \"angular\",\n",
    "        \"L\": 60,\n",
    "        \"k\": 3\n",
    "      }\n",
    "    },\n",
    "    \"imVecXpack\": {\n",
    "      \"type\": \"dense_vector\",\n",
    "      \"dims\": vector_dims\n",
    "    },\n",
    "    \"title\": { \"type\": \"text\" },\n",
    "    \"description\": { \"type\": \"text\" },\n",
    "    \"price\": { \"type\": \"float\" },\n",
    "    \"imUrl\": { \"type\": \"text\" }\n",
    "  }\n",
    "}\n",
    "\n",
    "if not es.indices.exists(index):\n",
    "  es.indices.create(index, settings)\n",
    "  es.indices.put_mapping(mapping, index)\n",
    "es.indices.get_mapping(index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
